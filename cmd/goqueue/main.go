// =============================================================================
// GOQUEUE MAIN ENTRY POINT
// =============================================================================
//
// This is the entry point for the goqueue broker. It demonstrates:
//   - Creating a broker with default configuration
//   - Creating multi-partition topics
//   - Using the Producer with client-side batching
//   - Message routing via consistent hashing (Murmur3)
//   - HTTP API server for external access
//   - Consuming messages from partitions
//   - Graceful shutdown
//
// MILESTONE 2 FEATURES DEMONSTRATED:
//   - Multi-partition topics (default 3 partitions)
//   - Producer batching (100 msgs, 5ms linger, 64KB)
//   - Murmur3 hash partitioning for message key routing
//   - HTTP REST API (create topics, publish, consume)
//
// =============================================================================

package main

import (
	"context"
	"fmt"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"goqueue/internal/api"
	"goqueue/internal/broker"
	"goqueue/internal/grpc"
)

func main() {
	fmt.Println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
	fmt.Println("â•‘                     GoQueue v0.2.0                            â•‘")
	fmt.Println("â•‘          Milestone 2: Topics, Partitions & Producer           â•‘")
	fmt.Println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
	fmt.Println()

	// -------------------------------------------------------------------------
	// STEP 1: Create broker with default configuration
	// -------------------------------------------------------------------------
	// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
	// â”‚ The Broker is the central component that:                               â”‚
	// â”‚   - Manages all topics and their partitions                             â”‚
	// â”‚   - Handles message persistence via the storage engine (M1)             â”‚
	// â”‚   - Coordinates producers and consumers                                 â”‚
	// â”‚                                                                         â”‚
	// â”‚ COMPARISON:                                                             â”‚
	// â”‚   - Kafka: Broker is a JVM process, typically 3+ in a cluster           â”‚
	// â”‚   - RabbitMQ: Broker = the entire RabbitMQ node                         â”‚
	// â”‚   - goqueue: Single broker for now (clustering in M10-M11)              â”‚
	// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	fmt.Println("ğŸ“¦ Starting broker...")
	config := broker.DefaultBrokerConfig()
	config.DataDir = "./data" // Store data in ./data directory

	b, err := broker.NewBroker(config)
	if err != nil {
		log.Fatalf("Failed to create broker: %v", err)
	}
	defer b.Close()

	fmt.Printf("   âœ“ Broker started (NodeID: %s)\n", b.NodeID())
	fmt.Printf("   âœ“ Data directory: %s\n\n", b.DataDir())

	// -------------------------------------------------------------------------
	// STEP 2: Create a multi-partition topic
	// -------------------------------------------------------------------------
	// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
	// â”‚ PARTITIONS - The Unit of Parallelism                                    â”‚
	// â”‚                                                                         â”‚
	// â”‚ A topic is split into partitions for:                                   â”‚
	// â”‚   1. PARALLELISM: Multiple consumers can read different partitions      â”‚
	// â”‚   2. ORDERING: Messages with same key go to same partition (ordered)    â”‚
	// â”‚   3. SCALABILITY: Partitions can be spread across nodes (future)        â”‚
	// â”‚                                                                         â”‚
	// â”‚ HOW IT WORKS:                                                           â”‚
	// â”‚   Producer â”€â”€â–º Topic â”€â”€â”¬â”€â”€ Partition 0 â”€â”€â–º Messages: A, D, G            â”‚
	// â”‚                        â”œâ”€â”€ Partition 1 â”€â”€â–º Messages: B, E, H            â”‚
	// â”‚                        â””â”€â”€ Partition 2 â”€â”€â–º Messages: C, F, I            â”‚
	// â”‚                                                                         â”‚
	// â”‚ ROUTING DECISION:                                                       â”‚
	// â”‚   - With key: hash(key) % numPartitions â†’ deterministic partition       â”‚
	// â”‚   - Without key: round-robin across partitions                          â”‚
	// â”‚                                                                         â”‚
	// â”‚ COMPARISON:                                                             â”‚
	// â”‚   - Kafka: Same model, partitions are fundamental unit                  â”‚
	// â”‚   - RabbitMQ: Queues (not partitions), different semantics              â”‚
	// â”‚   - SQS: FIFO queues have MessageGroupId (similar concept)              â”‚
	// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	topicName := "demo-orders"
	numPartitions := 3

	if !b.TopicExists(topicName) {
		fmt.Printf("ğŸ“ Creating topic '%s' with %d partitions...\n", topicName, numPartitions)
		err := b.CreateTopic(broker.TopicConfig{
			Name:          topicName,
			NumPartitions: numPartitions,
		})
		if err != nil {
			log.Fatalf("Failed to create topic: %v", err)
		}
		fmt.Printf("   âœ“ Topic created\n\n")
	} else {
		fmt.Printf("ğŸ“‚ Topic '%s' already exists\n\n", topicName)
	}

	// -------------------------------------------------------------------------
	// STEP 3: Create a Producer with batching
	// -------------------------------------------------------------------------
	// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
	// â”‚ PRODUCER BATCHING - Trading Latency for Throughput                      â”‚
	// â”‚                                                                         â”‚
	// â”‚ Instead of sending each message immediately:                            â”‚
	// â”‚   1. Messages accumulate in an in-memory buffer                         â”‚
	// â”‚   2. Batch is flushed when ANY trigger fires:                           â”‚
	// â”‚      - BatchSize reached (100 messages)                                 â”‚
	// â”‚      - LingerMs elapsed (5ms since first message)                       â”‚
	// â”‚      - BatchBytes exceeded (64KB total)                                 â”‚
	// â”‚                                                                         â”‚
	// â”‚ FLOW:                                                                   â”‚
	// â”‚   Send() â”€â”€â–º Batch Buffer â”€â”€[trigger]â”€â”€â–º Flush to Broker               â”‚
	// â”‚                 â”‚                                                       â”‚
	// â”‚                 â”œâ”€â”€ size >= 100?    â”€â”€â–º flush                           â”‚
	// â”‚                 â”œâ”€â”€ age >= 5ms?     â”€â”€â–º flush                           â”‚
	// â”‚                 â””â”€â”€ bytes >= 64KB?  â”€â”€â–º flush                           â”‚
	// â”‚                                                                         â”‚
	// â”‚ COMPARISON:                                                             â”‚
	// â”‚   - Kafka: Same model (batch.size, linger.ms)                           â”‚
	// â”‚   - RabbitMQ: Publisher confirms, no client batching                    â”‚
	// â”‚   - SQS: SendMessageBatch (max 10 messages)                             â”‚
	// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	fmt.Println("ğŸš€ Creating Producer with batching enabled...")
	producerConfig := broker.ProducerConfig{
		Topic:      topicName,
		BatchSize:  10,        // Smaller for demo (normally 100)
		LingerMs:   50,        // 50ms - longer for demo visibility
		BatchBytes: 64 * 1024, // 64KB
		AckMode:    broker.AckLeader,
	}

	producer, err := broker.NewProducer(b, producerConfig)
	if err != nil {
		log.Fatalf("Failed to create producer: %v", err)
	}
	defer producer.Close()

	fmt.Printf("   âœ“ Producer started (BatchSize=%d, LingerMs=%dms, AckMode=%s)\n\n",
		producerConfig.BatchSize, producerConfig.LingerMs, producerConfig.AckMode)

	// -------------------------------------------------------------------------
	// STEP 4: Publish messages with keys (demonstrates partitioning)
	// -------------------------------------------------------------------------
	// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
	// â”‚ KEY-BASED PARTITIONING - Ordering Guarantee                             â”‚
	// â”‚                                                                         â”‚
	// â”‚ When you provide a message key:                                         â”‚
	// â”‚   partition = murmur3(key) % numPartitions                              â”‚
	// â”‚                                                                         â”‚
	// â”‚ This ensures:                                                           â”‚
	// â”‚   - Same key ALWAYS goes to same partition                              â”‚
	// â”‚   - Messages for same key are ORDERED                                   â”‚
	// â”‚   - Different keys may share partitions (hash collisions)               â”‚
	// â”‚                                                                         â”‚
	// â”‚ EXAMPLE (3 partitions):                                                 â”‚
	// â”‚   "user-100" â†’ murmur3 â†’ partition 0                                    â”‚
	// â”‚   "user-200" â†’ murmur3 â†’ partition 2                                    â”‚
	// â”‚   "user-300" â†’ murmur3 â†’ partition 1                                    â”‚
	// â”‚   "user-100" â†’ murmur3 â†’ partition 0 (SAME!)                            â”‚
	// â”‚                                                                         â”‚
	// â”‚ WHY MURMUR3:                                                            â”‚
	// â”‚   - Fast (non-cryptographic)                                            â”‚
	// â”‚   - Excellent distribution (uniform across partitions)                  â”‚
	// â”‚   - Industry standard (Kafka default)                                   â”‚
	// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	fmt.Println("ğŸ“¤ Publishing messages with keys (observing partition routing)...")
	messages := []struct {
		Key   string
		Value string
	}{
		// Orders from different users - should go to consistent partitions
		{"user-100", `{"order": "A", "user": "100", "product": "Widget"}`},
		{"user-200", `{"order": "B", "user": "200", "product": "Gadget"}`},
		{"user-300", `{"order": "C", "user": "300", "product": "Gizmo"}`},
		{"user-100", `{"order": "D", "user": "100", "product": "Sprocket"}`}, // Same user as A
		{"user-200", `{"order": "E", "user": "200", "product": "Cog"}`},      // Same user as B
		{"user-100", `{"order": "F", "user": "100", "product": "Bolt"}`},     // Same user as A, D
	}

	// Track which partition each user goes to
	userPartitions := make(map[string]int)

	for _, msg := range messages {
		// Use synchronous send for demo (easier to show partition assignment)
		ctx := context.Background()
		result := producer.SendSync(ctx, broker.ProducerRecord{
			Key:   []byte(msg.Key),
			Value: []byte(msg.Value),
		})
		if result.Error != nil {
			log.Printf("   âœ— Failed to publish: %v", result.Error)
			continue
		}

		partition := result.Partition
		offset := result.Offset

		// Track partition for this user
		if existing, ok := userPartitions[msg.Key]; ok {
			if existing != partition {
				fmt.Printf("   âš  PARTITION MISMATCH for %s! (expected %d, got %d)\n",
					msg.Key, existing, partition)
			}
		} else {
			userPartitions[msg.Key] = partition
		}

		fmt.Printf("   âœ“ key=%-10s â†’ partition=%d, offset=%d\n", msg.Key, partition, offset)
	}

	fmt.Println("\n   ğŸ“Š Partition Assignment Summary:")
	for user, part := range userPartitions {
		fmt.Printf("      %s â†’ Partition %d\n", user, part)
	}
	fmt.Println()

	// -------------------------------------------------------------------------
	// STEP 5: Consume messages from each partition
	// -------------------------------------------------------------------------
	fmt.Println("ğŸ“¥ Consuming messages from each partition...")
	for p := 0; p < numPartitions; p++ {
		consumed, err := b.Consume(topicName, p, 0, 100)
		if err != nil {
			log.Printf("   âœ— Failed to consume from partition %d: %v", p, err)
			continue
		}

		fmt.Printf("\n   Partition %d (%d messages):\n", p, len(consumed))
		for _, m := range consumed {
			key := string(m.Key)
			if key == "" {
				key = "(no key)"
			}
			fmt.Printf("      [offset=%d] key=%s\n", m.Offset, key)
		}
	}
	fmt.Println()

	// -------------------------------------------------------------------------
	// STEP 6: Start HTTP API Server
	// -------------------------------------------------------------------------
	// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
	// â”‚ HTTP API - External Access to GoQueue                                   â”‚
	// â”‚                                                                         â”‚
	// â”‚ Endpoints:                                                              â”‚
	// â”‚   GET  /health                              - Health check              â”‚
	// â”‚   GET  /stats                               - Broker statistics         â”‚
	// â”‚   POST /topics                              - Create topic              â”‚
	// â”‚   GET  /topics                              - List topics               â”‚
	// â”‚   GET  /topics/{name}                       - Get topic info            â”‚
	// â”‚   DELETE /topics/{name}                     - Delete topic              â”‚
	// â”‚   POST /topics/{name}/messages              - Publish messages          â”‚
	// â”‚   GET  /topics/{name}/partitions/{id}/msgs  - Consume messages          â”‚
	// â”‚                                                                         â”‚
	// â”‚ COMPARISON:                                                             â”‚
	// â”‚   - Kafka: Binary protocol (librdkafka), REST proxy separate            â”‚
	// â”‚   - RabbitMQ: AMQP protocol, HTTP management API                        â”‚
	// â”‚   - SQS: HTTP/REST API                                                  â”‚
	// â”‚   - goqueue: REST-first (gRPC planned for M14)                          â”‚
	// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	fmt.Println("ğŸŒ Starting HTTP API server...")
	serverConfig := api.DefaultServerConfig()
	serverConfig.Addr = "127.0.0.1:8080"

	server := api.NewServer(b, serverConfig)
	if err := server.Start(); err != nil {
		log.Fatalf("Failed to start HTTP server: %v", err)
	}

	fmt.Printf("   âœ“ HTTP API listening on http://%s\n", serverConfig.Addr)
	fmt.Println()

	// -------------------------------------------------------------------------
	// STEP 6b: Start gRPC Server (M15)
	// -------------------------------------------------------------------------
	// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
	// â”‚ gRPC API - High-Performance Binary Protocol                             â”‚
	// â”‚                                                                         â”‚
	// â”‚ WHY gRPC alongside HTTP:                                                â”‚
	// â”‚   - HTTP: Easy debugging, curl-friendly, wide compatibility             â”‚
	// â”‚   - gRPC: High performance, streaming, type-safe (for hot path)         â”‚
	// â”‚                                                                         â”‚
	// â”‚ gRPC Services:                                                          â”‚
	// â”‚   PublishService  - Message publishing (unary + streaming)              â”‚
	// â”‚   ConsumeService  - Message consuming (streaming)                       â”‚
	// â”‚   AckService      - Message acknowledgment                              â”‚
	// â”‚   OffsetService   - Consumer offset management                          â”‚
	// â”‚   HealthService   - Health checking (gRPC standard)                     â”‚
	// â”‚                                                                         â”‚
	// â”‚ COMPARISON:                                                             â”‚
	// â”‚   - Kafka: Custom binary protocol over TCP                              â”‚
	// â”‚   - RabbitMQ: AMQP protocol (binary)                                    â”‚
	// â”‚   - NATS: Custom binary protocol                                        â”‚
	// â”‚   - goqueue: gRPC/HTTP2 with Protocol Buffers                           â”‚
	// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
	fmt.Println("ğŸ”Œ Starting gRPC server...")

	grpcConfig := grpc.DefaultServerConfig()
	grpcConfig.Address = "127.0.0.1:9000"
	grpcConfig.EnableReflection = true // Enable for debugging with grpcurl

	grpcServer := grpc.NewServer(b, grpcConfig)
	if err := grpcServer.Start(); err != nil {
		log.Fatalf("Failed to start gRPC server: %v", err)
	}

	fmt.Printf("   âœ“ gRPC API listening on %s\n", grpcConfig.Address)
	fmt.Println()

	fmt.Println("   Try these commands:")
	fmt.Println("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
	fmt.Println("   â”‚ HTTP API (debugging):                                                  â”‚")
	fmt.Println("   â”‚   curl http://localhost:8080/health                                    â”‚")
	fmt.Println("   â”‚   curl http://localhost:8080/stats                                     â”‚")
	fmt.Println("   â”‚   curl http://localhost:8080/topics                                    â”‚")
	fmt.Println("   â”‚   curl -X POST -d '{\"name\":\"test\"}' http://localhost:8080/topics    â”‚")
	fmt.Println("   â”‚                                                                        â”‚")
	fmt.Println("   â”‚ gRPC API (high performance):                                           â”‚")
	fmt.Println("   â”‚   Use the goqueue Go client for gRPC operations                        â”‚")
	fmt.Println("   â”‚   grpcurl -plaintext localhost:9000 list                               â”‚")
	fmt.Println("   â”‚   grpcurl -plaintext localhost:9000 goqueue.v1.HealthService/Check     â”‚")
	fmt.Println("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
	fmt.Println()

	// -------------------------------------------------------------------------
	// STEP 7: Show statistics
	// -------------------------------------------------------------------------
	fmt.Println("ğŸ“Š Broker Statistics:")
	stats := b.Stats()
	fmt.Printf("   Node ID:     %s\n", stats.NodeID)
	fmt.Printf("   Uptime:      %s\n", stats.Uptime.Round(time.Millisecond))
	fmt.Printf("   Topics:      %d\n", stats.TopicCount)
	fmt.Printf("   Total Size:  %d bytes\n", stats.TotalSize)
	for name, ts := range stats.TopicStats {
		fmt.Printf("\n   Topic '%s':\n", name)
		fmt.Printf("     Partitions: %d\n", ts.Partitions)
		fmt.Printf("     Messages:   %d\n", ts.TotalMessages)
		fmt.Printf("     Size:       %d bytes\n", ts.TotalSize)
	}

	// -------------------------------------------------------------------------
	// STEP 8: Wait for interrupt (server mode)
	// -------------------------------------------------------------------------
	fmt.Println()
	fmt.Println("ğŸš€ GoQueue running. Press Ctrl+C to stop.")

	// Set up signal handling for graceful shutdown
	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)
	<-sigCh

	fmt.Println("\n\nğŸ›‘ Shutting down...")

	// Graceful shutdown with timeout
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	// Stop gRPC server first (handles in-flight RPCs)
	grpcServer.Stop()
	fmt.Println("   âœ“ gRPC server stopped")

	// Stop HTTP server
	if err := server.Stop(ctx); err != nil {
		log.Printf("HTTP server shutdown error: %v", err)
	}
	fmt.Println("   âœ“ HTTP server stopped")

	fmt.Println("   âœ“ Shutdown complete")
}
